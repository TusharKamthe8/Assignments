{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d17c1ec-148a-4e62-b507-0f3b87608a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question No-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68dcc7b7-c031-44f3-aa36-b8bb2b270d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\n    1) Web Scraping- Web scraping is an method in which we obtain large amounts of data from websites. This process is fully automated.\\n    \\n    2) When we want lot's of data from a awebsite which is in a unstructured manner. In such cases web scraping is used.It helps to innovate\\n       lot's of things. Also the data which is being generated at this scale gets some usage for more improvised user experience.\\n       \\n    3) Web scrapping is used in areas such as-\\n            a)Market Research,\\n            b)Sentimental Analysis.\\n            c)Email Marketing. \""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "    1) Web Scraping- Web scraping is an method in which we obtain large amounts of data from websites. This process is fully automated.\n",
    "    \n",
    "    2) When we want lot's of data from a awebsite which is in a unstructured manner. In such cases web scraping is used.It helps to innovate\n",
    "       lot's of things. Also the data which is being generated at this scale gets some usage for more improvised user experience.\n",
    "       \n",
    "    3) Web scrapping is used in areas such as-\n",
    "            a)Market Research,\n",
    "            b)Sentimental Analysis.\n",
    "            c)Email Marketing. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "388c2c7d-1f74-4764-9cf9-bff3f24d750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question No-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88c784d5-d75a-4ade-8dcc-9a9088c5b788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    The different methods used for web scraping are-\\n            1) Copy pasting.\\n            2) DOM parsing\\n            3) HTTP programming.\\n            4) Text grepping.\\n            5) Web scarping software. '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    The different methods used for web scraping are-\n",
    "            1) Copy pasting.\n",
    "            2) DOM parsing\n",
    "            3) HTTP programming.\n",
    "            4) Text grepping.\n",
    "            5) Web scarping software. \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61f3636d-7c15-4ef9-8b6b-8e8db947bcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question No-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dd563e3-1ad5-4f4c-802c-4fa1ad51a869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    1) Beautiful soup- Beautiful Soup is a python package which parses the unwanted data. It gives us an more cleaner data by organising and \\n                    formatting data. It fixes the HTML and makes it available for further usage.\\n                    \\n    2) Beautiful soup is used in web scraping where the HTML data obatined from websites is messy in such cases beautiful soup helps to the\\n       data in a more better readable manner. '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    1) Beautiful soup- Beautiful Soup is a python package which parses the unwanted data. It gives us an more cleaner data by organising and \n",
    "                    formatting data. It fixes the HTML and makes it available for further usage.\n",
    "                    \n",
    "    2) Beautiful soup is used in web scraping where the HTML data obatined from websites is messy in such cases beautiful soup helps to the\n",
    "       data in a more better readable manner. \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "883c018a-d086-4a72-b02a-79d0984de764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question No-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e069ebf-1ec9-4604-8082-8962904a5a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Flask is used as an framework in this project upon which the web application is built. Flask is scalable, flexible, lightweight\\n    which makes us more reliable to work upon in this project. It gets us to implement our REST architecture which is the main whole and sole \\n    of this project. '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Flask is used as an framework in this project upon which the web application is built. Flask is scalable, flexible, lightweight\n",
    "    which makes us more reliable to work upon in this project. It gets us to implement our REST architecture which is the main whole and sole \n",
    "    of this project. \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1aeaa61f-69a0-43eb-8b3a-1a519e7650c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question No-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fbd887-cf6d-4059-a058-a033cb835458",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    1) The AWS services used in this project are 'Elastic Beanstalk' and 'CodePipeline'.\n",
    "    \n",
    "    2) Elastic Beanstalk- Elastic beanstalk is a pre-configured EC2 server that can directly take up your application code and environment\n",
    "                          configurations and use it to automatically provision and deploy the required resources within AWS to run the web \n",
    "                          application.\n",
    "    \n",
    "    3) CodePipeline- AWS CodePipeline is a continuous delivery service you can use to model, visualize, and automate the steps required \n",
    "                     to release your software. You can quickly model and configure the different stages of a software release process. \n",
    "                     CodePipeline automates the steps required to release your software changes continuously. \"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
